name: Run Scrape Script

on:
  schedule:
    - cron: '0 0 * * *' # Runs daily at midnight UTC
  workflow_dispatch: # Allows manual trigger from GitHub UI

permissions:
  contents: write

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout the code
    - name: Checkout code
      uses: actions/checkout@v3

    # Step 2: Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # Step 4: Run the scrape.py script
    - name: Run scrape.py
      run: python scrape.py

    # Step 5: Upload the output directory as an artifact
    - name: Upload output directory
      uses: actions/upload-artifact@v4
      with:
        name: generated-output
        path: output/

    # Optional: Commit and push changes to the repository
    - name: Commit and Push Changes
      if: always()
      run: |
        git config user.name "GitHub Actions"
        git config user.email "actions@github.com"
        git add output/
        git commit -m "Update generated output"
        git push origin main
